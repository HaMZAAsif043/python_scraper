{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e34df8b",
   "metadata": {},
   "source": [
    "# Coffee Shop Data Analysis System Demo\n",
    "\n",
    "This notebook demonstrates how to use the coffee shop data analysis system to collect, process, analyze, and visualize data about coffee shops in Pakistan using free resources.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69a7cb16",
   "metadata": {},
   "source": [
    "## 1. Setup\n",
    "\n",
    "First, let's make sure we have all the required dependencies installed:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae7adb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install beautifulsoup4 requests pandas matplotlib seaborn plotly statsmodels scikit-learn scipy python-dotenv schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c9c20c",
   "metadata": {},
   "source": [
    "Next, let's import the necessary modules and set up the paths to access our code:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6999879",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Add the project root to Python path so we can import our modules\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), '..'))\n",
    "sys.path.append(project_root)\n",
    "\n",
    "# Import project modules\n",
    "from src.config import TARGET_LOCATIONS, PATHS\n",
    "from src.data_collection.google_maps import collect_google_maps_data\n",
    "from src.data_collection.social_media import collect_social_media_data\n",
    "from src.data_collection.food_delivery import collect_food_delivery_data\n",
    "from src.data_collection.market_trends import collect_market_trends_data\n",
    "from src.visualization.dashboard import CoffeeShopVisualizer, create_visualizations\n",
    "\n",
    "# Set up timestamp for this run\n",
    "timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "print(f\"Notebook execution timestamp: {timestamp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0e6178",
   "metadata": {},
   "source": [
    "## 2. Data Collection\n",
    "\n",
    "Now let's collect data from various sources. All of these modules have been modified to use free resources instead of paid APIs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984b1b19",
   "metadata": {},
   "source": [
    "### 2.1 Collect Google Maps Data\n",
    "\n",
    "This module uses web scraping to extract coffee shop information from Google Maps instead of using the paid Google Maps API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c959be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect data from Google Maps using web scraping\n",
    "google_data = collect_google_maps_data()\n",
    "\n",
    "# Preview the first city's data\n",
    "first_city = list(google_data.keys())[0]\n",
    "print(f\"Collected data for {len(google_data)} cities.\")\n",
    "print(f\"Found {len(google_data[first_city])} coffee shops in {first_city}.\")\n",
    "\n",
    "# Show one sample coffee shop\n",
    "if google_data[first_city]:\n",
    "    sample_shop = google_data[first_city][0]\n",
    "    print(\"\\nSample coffee shop data:\")\n",
    "    print(f\"Name: {sample_shop.get('name')}\")\n",
    "    print(f\"Rating: {sample_shop.get('rating')}\")\n",
    "    print(f\"Address: {sample_shop.get('address')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6685a28a",
   "metadata": {},
   "source": [
    "### 2.2 Collect Social Media Data\n",
    "\n",
    "This module generates simulated Twitter/X data about coffee shops since we don't have access to the paid Twitter API.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577426cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect simulated social media data\n",
    "social_data = collect_social_media_data()\n",
    "\n",
    "# Preview the data\n",
    "print(f\"Collected {len(social_data.get('twitter', {}).get('tweets', []))} tweets related to coffee shops.\")\n",
    "\n",
    "# Display a few sample tweets\n",
    "if 'twitter' in social_data and 'tweets' in social_data['twitter']:\n",
    "    print(\"\\nSample tweets:\")\n",
    "    for i, tweet in enumerate(social_data['twitter']['tweets'][:3]):\n",
    "        print(f\"{i+1}. {tweet.get('username')}: {tweet.get('text')}\")\n",
    "\n",
    "# Show top hashtags if available\n",
    "if 'twitter' in social_data and 'hashtags' in social_data['twitter']:\n",
    "    print(\"\\nTop hashtags:\")\n",
    "    for i, (tag, count) in enumerate(social_data['twitter']['hashtags'].items()):\n",
    "        if i < 5:  # Show only top 5\n",
    "            print(f\"{tag}: {count} mentions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0447f37",
   "metadata": {},
   "source": [
    "### 2.3 Collect Food Delivery Data\n",
    "\n",
    "This module simulates data from food delivery platforms based on realistic patterns for coffee shops in Pakistan.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86137372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect simulated food delivery data\n",
    "delivery_data = collect_food_delivery_data()\n",
    "\n",
    "# Preview the data\n",
    "print(f\"Collected food delivery data for {len(delivery_data)} cities.\")\n",
    "\n",
    "# Show sample coffee menu items and pricing\n",
    "if delivery_data and first_city in delivery_data and delivery_data[first_city]:\n",
    "    sample_shop = delivery_data[first_city][0]\n",
    "    print(f\"\\nSample coffee shop: {sample_shop.get('name')}\")\n",
    "    print(\"Menu items:\")\n",
    "    for item in sample_shop.get('menu_items', []):\n",
    "        print(f\"  - {item.get('name')}: Rs. {item.get('price')} ({item.get('description')})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81d05b2",
   "metadata": {},
   "source": [
    "### 2.4 Collect Market Trends Data\n",
    "\n",
    "This module collects market trend data about the coffee industry from free public datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebdcab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect market trends data from free sources\n",
    "market_data = collect_market_trends_data()\n",
    "\n",
    "# Preview the data\n",
    "print(\"Market trend data categories:\")\n",
    "for category in market_data.keys():\n",
    "    print(f\"- {category}\")\n",
    "\n",
    "# Show coffee price trends if available\n",
    "if 'coffee_prices' in market_data:\n",
    "    prices = market_data['coffee_prices']\n",
    "    print(\"\\nCoffee price trends:\")\n",
    "    for entry in prices[:5]:  # Show first 5 entries\n",
    "        print(f\"{entry.get('date')}: ${entry.get('price')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fccfaf",
   "metadata": {},
   "source": [
    "## 3. Data Visualization\n",
    "\n",
    "Now let's create some visualizations of our data. We'll use the free visualization libraries we've integrated.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c38f8e6",
   "metadata": {},
   "source": [
    "### 3.1 Coffee Shop Distribution by City\n",
    "\n",
    "Let's create a bar chart showing coffee shop distribution across Pakistani cities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6f5f72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame with shop counts per city\n",
    "city_counts = []\n",
    "for city, shops in google_data.items():\n",
    "    city_counts.append({\"city\": city, \"count\": len(shops)})\n",
    "\n",
    "city_df = pd.DataFrame(city_counts)\n",
    "\n",
    "# Create the visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.barplot(data=city_df, x=\"city\", y=\"count\")\n",
    "\n",
    "# Add value labels on top of bars\n",
    "for i, v in enumerate(city_df[\"count\"]):\n",
    "    ax.text(i, v + 0.1, str(v), ha=\"center\")\n",
    "\n",
    "plt.title(\"Coffee Shop Distribution by City in Pakistan\", fontsize=16)\n",
    "plt.xlabel(\"City\", fontsize=12)\n",
    "plt.ylabel(\"Number of Coffee Shops\", fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d065879",
   "metadata": {},
   "source": [
    "### 3.2 Coffee Price Analysis\n",
    "\n",
    "Let's analyze coffee prices from our food delivery data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d3e9455",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract coffee prices from different cities\n",
    "coffee_prices = []\n",
    "for city, shops in delivery_data.items():\n",
    "    for shop in shops:\n",
    "        for item in shop.get('menu_items', []):\n",
    "            if item.get('name') == 'Espresso':  # Focus on one coffee type\n",
    "                coffee_prices.append({\n",
    "                    \"city\": city,\n",
    "                    \"shop\": shop.get('name'),\n",
    "                    \"price\": item.get('price')\n",
    "                })\n",
    "\n",
    "price_df = pd.DataFrame(coffee_prices)\n",
    "\n",
    "# Create a boxplot to compare prices across cities\n",
    "plt.figure(figsize=(14, 8))\n",
    "ax = sns.boxplot(data=price_df, x=\"city\", y=\"price\")\n",
    "plt.title(\"Espresso Prices Across Pakistani Cities\", fontsize=16)\n",
    "plt.xlabel(\"City\", fontsize=12)\n",
    "plt.ylabel(\"Price (PKR)\", fontsize=12)\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate and display average prices\n",
    "avg_prices = price_df.groupby('city')['price'].mean().sort_values(ascending=False)\n",
    "print(\"Average Espresso Prices by City (PKR):\")\n",
    "for city, price in avg_prices.items():\n",
    "    print(f\"{city}: {price:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855c895e",
   "metadata": {},
   "source": [
    "### 3.3 Social Media Analysis\n",
    "\n",
    "Let's visualize some insights from our social media data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a386cf51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract hashtags and their counts\n",
    "if 'twitter' in social_data and 'hashtags' in social_data['twitter']:\n",
    "    hashtags = []\n",
    "    for tag, count in social_data['twitter']['hashtags'].items():\n",
    "        hashtags.append({\"tag\": tag, \"count\": count})\n",
    "    \n",
    "    # Convert to DataFrame and sort by count\n",
    "    hashtag_df = pd.DataFrame(hashtags)\n",
    "    hashtag_df = hashtag_df.sort_values('count', ascending=False).head(10)  # Top 10\n",
    "    \n",
    "    # Create the visualization\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    ax = sns.barplot(data=hashtag_df, y=\"tag\", x=\"count\", palette='viridis')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(hashtag_df['count']):\n",
    "        ax.text(v + 0.1, i, str(v), va='center')\n",
    "    \n",
    "    plt.title('Top Coffee-Related Hashtags on Social Media', fontsize=16)\n",
    "    plt.xlabel('Number of Mentions', fontsize=12)\n",
    "    plt.ylabel('Hashtag', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30111eea",
   "metadata": {},
   "source": [
    "### 3.4 Generate Complete Dashboard\n",
    "\n",
    "Let's create a complete dashboard using our visualization module.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b690245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we need to save our collected data to the expected locations\n",
    "# This simulates what the main pipeline would do\n",
    "\n",
    "base_dir = os.path.dirname(os.path.dirname(os.path.abspath('__file__')))\n",
    "raw_dir = os.path.join(base_dir, PATHS['raw_data'])\n",
    "processed_dir = os.path.join(base_dir, PATHS['processed_data'])\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(raw_dir, exist_ok=True)\n",
    "os.makedirs(processed_dir, exist_ok=True)\n",
    "\n",
    "# Save the raw data\n",
    "with open(os.path.join(raw_dir, f\"google_maps_{timestamp}.json\"), 'w') as f:\n",
    "    json.dump(google_data, f, indent=2)\n",
    "\n",
    "with open(os.path.join(raw_dir, f\"social_media_{timestamp}.json\"), 'w') as f:\n",
    "    json.dump(social_data, f, indent=2)\n",
    "    \n",
    "with open(os.path.join(raw_dir, f\"food_delivery_{timestamp}.json\"), 'w') as f:\n",
    "    json.dump(delivery_data, f, indent=2)\n",
    "    \n",
    "with open(os.path.join(raw_dir, f\"market_trends_{timestamp}.json\"), 'w') as f:\n",
    "    json.dump(market_data, f, indent=2)\n",
    "\n",
    "print(\"Raw data saved to files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f1ad24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now create an analysis directory with some sample analysis results\n",
    "# In a real pipeline these would come from the analysis modules\n",
    "analysis_dir = os.path.join(processed_dir, f\"analysis_{timestamp}\")\n",
    "os.makedirs(analysis_dir, exist_ok=True)\n",
    "\n",
    "# Create sample statistical analysis results\n",
    "statistical_results = {\n",
    "    \"city_analysis\": {\n",
    "        \"google_maps\": {\n",
    "            \"shop_count_by_city\": [\n",
    "                {\"city\": city, \"coffee_shop_count\": len(shops)} \n",
    "                for city, shops in google_data.items()\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"review_analysis\": {\n",
    "        \"google_maps\": {\n",
    "            \"rating_distribution\": [\n",
    "                {\"rating\": r, \"count\": sum(1 for city in google_data.values() for shop in city if shop.get('rating', 0) == r)}\n",
    "                for r in [3.0, 3.5, 4.0, 4.5, 5.0]\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"pricing_analysis\": {\n",
    "        \"coffee_menu_items\": {\n",
    "            \"city_comparison\": [\n",
    "                {\n",
    "                    \"name\": \"Espresso\",\n",
    "                    \"Karachi\": 250,\n",
    "                    \"Lahore\": 230,\n",
    "                    \"Islamabad\": 280\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"Cappuccino\",\n",
    "                    \"Karachi\": 400,\n",
    "                    \"Lahore\": 380,\n",
    "                    \"Islamabad\": 420\n",
    "                },\n",
    "                {\n",
    "                    \"name\": \"Latte\",\n",
    "                    \"Karachi\": 450,\n",
    "                    \"Lahore\": 430,\n",
    "                    \"Islamabad\": 470\n",
    "                }\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the statistical analysis\n",
    "with open(os.path.join(analysis_dir, 'statistical_analysis.json'), 'w') as f:\n",
    "    json.dump(statistical_results, f, indent=2)\n",
    "\n",
    "# Create sample trend analysis results\n",
    "trend_results = {\n",
    "    \"price_trends\": {\n",
    "        \"coffee_price\": {\n",
    "            \"forecast\": {\n",
    "                \"forecast\": [\n",
    "                    {\"date\": \"2025-01\", \"value\": 100},\n",
    "                    {\"date\": \"2025-02\", \"value\": 102},\n",
    "                    {\"date\": \"2025-03\", \"value\": 105},\n",
    "                    {\"date\": \"2025-04\", \"value\": 110},\n",
    "                    {\"date\": \"2025-05\", \"value\": 112},\n",
    "                    {\"date\": \"2025-06\", \"value\": 115}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    \"consumption_trends\": {\n",
    "        \"forecast\": {\n",
    "            \"next_3_years\": [\n",
    "                {\"year\": \"2025\", \"value\": 1200},\n",
    "                {\"year\": \"2026\", \"value\": 1350},\n",
    "                {\"year\": \"2027\", \"value\": 1500}\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"social_media_trends\": {\n",
    "        \"hashtags\": {\n",
    "            \"top_10\": [\n",
    "                {\"tag\": \"#CoffeeLover\", \"mentions\": 145},\n",
    "                {\"tag\": \"#PakistaniCafe\", \"mentions\": 98},\n",
    "                {\"tag\": \"#MorningCoffee\", \"mentions\": 87},\n",
    "                {\"tag\": \"#CafeHopping\", \"mentions\": 76},\n",
    "                {\"tag\": \"#LahoreEats\", \"mentions\": 65},\n",
    "                {\"tag\": \"#IslamabadCafe\", \"mentions\": 54},\n",
    "                {\"tag\": \"#KarachiCoffee\", \"mentions\": 43},\n",
    "                {\"tag\": \"#CoffeeTime\", \"mentions\": 32},\n",
    "                {\"tag\": \"#CafeVibes\", \"mentions\": 28},\n",
    "                {\"tag\": \"#BrewedCoffee\", \"mentions\": 22}\n",
    "            ]\n",
    "        }\n",
    "    },\n",
    "    \"competitor_trends\": {\n",
    "        \"market_share\": [\n",
    "            {\"category\": \"International Chains\", \"market_share\": 35},\n",
    "            {\"category\": \"Local Premium Brands\", \"market_share\": 25},\n",
    "            {\"category\": \"Mid-market Cafes\", \"market_share\": 20},\n",
    "            {\"category\": \"Independent Shops\", \"market_share\": 15},\n",
    "            {\"category\": \"Tea & Coffee Houses\", \"market_share\": 5}\n",
    "        ]\n",
    "    }\n",
    "}\n",
    "\n",
    "# Save the trend analysis\n",
    "with open(os.path.join(analysis_dir, 'trend_analysis.json'), 'w') as f:\n",
    "    json.dump(trend_results, f, indent=2)\n",
    "\n",
    "print(\"Sample analysis results created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df3d8ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can generate a dashboard using our visualization module\n",
    "visualization_results = create_visualizations(timestamp=timestamp)\n",
    "\n",
    "if visualization_results and 'dashboard' in visualization_results:\n",
    "    dashboard_path = visualization_results['dashboard']\n",
    "    print(f\"Dashboard successfully created at: {dashboard_path}\")\n",
    "    \n",
    "    # In a Jupyter notebook, we can display the HTML directly\n",
    "    from IPython.display import IFrame\n",
    "    IFrame(src=dashboard_path, width=1000, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8dfd6c9",
   "metadata": {},
   "source": [
    "## 4. Advanced Analysis Example: Price Correlation with Ratings\n",
    "\n",
    "Let's perform a simple analysis to see if there's any correlation between coffee prices and shop ratings.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e0bacf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine price data with ratings\n",
    "price_rating_data = []\n",
    "\n",
    "for city, shops in delivery_data.items():\n",
    "    for shop in shops:\n",
    "        # Get the average price of all coffee items\n",
    "        if 'menu_items' in shop:\n",
    "            avg_price = sum(item.get('price', 0) for item in shop['menu_items']) / len(shop['menu_items'])\n",
    "            \n",
    "            price_rating_data.append({\n",
    "                \"shop_name\": shop.get('name'),\n",
    "                \"city\": city,\n",
    "                \"rating\": shop.get('rating', 0),\n",
    "                \"avg_price\": avg_price\n",
    "            })\n",
    "\n",
    "# Convert to DataFrame\n",
    "pr_df = pd.DataFrame(price_rating_data)\n",
    "\n",
    "# Create a scatter plot\n",
    "plt.figure(figsize=(12, 8))\n",
    "ax = sns.scatterplot(data=pr_df, x=\"avg_price\", y=\"rating\", hue=\"city\", s=100, alpha=0.7)\n",
    "\n",
    "# Add a trend line\n",
    "sns.regplot(data=pr_df, x=\"avg_price\", y=\"rating\", scatter=False, ax=ax, color=\"black\")\n",
    "\n",
    "plt.title(\"Correlation Between Coffee Prices and Shop Ratings\", fontsize=16)\n",
    "plt.xlabel(\"Average Menu Price (PKR)\", fontsize=12)\n",
    "plt.ylabel(\"Rating\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Calculate correlation\n",
    "correlation = pr_df[['avg_price', 'rating']].corr().iloc[0, 1]\n",
    "print(f\"Correlation coefficient between price and rating: {correlation:.3f}\")\n",
    "\n",
    "# Interpretation\n",
    "if abs(correlation) < 0.3:\n",
    "    print(\"There is a weak correlation between coffee prices and ratings.\")\n",
    "elif abs(correlation) < 0.7:\n",
    "    print(\"There is a moderate correlation between coffee prices and ratings.\")\n",
    "else:\n",
    "    print(\"There is a strong correlation between coffee prices and ratings.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74898ea3",
   "metadata": {},
   "source": [
    "## 5. Conclusion and Next Steps\n",
    "\n",
    "In this notebook, we've demonstrated:\n",
    "\n",
    "1. How to collect coffee shop data using free resources (web scraping and simulated data)\n",
    "2. How to visualize and analyze this data using free Python libraries\n",
    "3. How to generate a comprehensive dashboard for coffee shop market analysis\n",
    "4. How to perform advanced analyses like price-rating correlation\n",
    "\n",
    "Next steps:\n",
    "\n",
    "1. Run the full data pipeline regularly using scheduled tasks\n",
    "2. Refine the data collection methods as needed\n",
    "3. Add more advanced analyses based on business questions\n",
    "4. Create custom reports for specific stakeholders\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
